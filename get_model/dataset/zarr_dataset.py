# %%
import zarr
import threading
import random
from numcodecs import Blosc
from caesar.io.zarr_io import DenseZarrIO, CelltypeDenseZarrIO
from tqdm import tqdm
from torch.utils.data import Dataset
from scipy.sparse import coo_matrix, load_npz, vstack
from get_model.dataset.splitter import cell_splitter, chromosome_splitter
from get_model.dataset.io import generate_paths, get_hierachical_ctcf_pos, prepare_sequence_idx
from scipy.sparse import csr_matrix
import pandas as pd
import time
import numpy as np
from glob import glob
import logging
import sys
from posixpath import basename
from queue import Queue
import os.path
sys.path.append('/manitou/pmg/users/xf2217/get_model')
# from augmentation import (
#     DataAugmentationForGETPeak,
#     DataAugmentationForGETPeakFinetune,
# )


class PretrainDataset(Dataset):
    def __init__(self, zarr_dirs, genome_seq_zarr, insulation_paths, preload_count=50, samples_per_window=50):
        super().__init__()
        """
        Pretrain dataset for GET model.

        This dataset is used to train the GET model in a self-supervised manner.
        It loads data from a set of zarr files and generates samples for training.
        Each sample consists of a track and a peak sequence extracted from a 4Mbp window.
        The track is a 2D sparse array of shape (nucleotide,1) and the peak sequence is a 2D array of shape (nucleotide,4). Peak sequence is generated by multiplying the peak mask with the genomic sequence. Track is cell-type specific ATAC-seq insertion counts per nucleotide, without any normalization. Peak sequence is a one-hot encoding of DNA. Other metadata about the sample is also included in the sample as a dictionary.

        Parameters:
        zarr_dirs (list): A list of paths to zarr files.
        genome_seq_zarr (str): Path to the genome sequence zarr file.
        insulation_paths (list): A list of paths to insulation data.
        preload_count (int): Number of windows to preload.
        samples_per_window (int): Number of samples to generate from each window.

        Attributes:
        zarr_dirs (list): A list of paths to zarr files.
        genome_seq_zarr (str): Path to the genome sequence zarr file.
        insulation_paths (list): A list of paths to insulation data.
        preload_count (int): Number of windows to preload.
        samples_per_window (int): Number of samples to generate from each window.
        sequence (DenseZarrIO): An instance of DenseZarrIO for genome sequence.
        zarr_dict (dict): A dictionary of CelltypeDenseZarrIO instances for zarr files.
        data_keys (list): A list of data keys for zarr files.
        n_celltypes (int): Number of cell types.
        chunk_size (int): Chunk size.
        chrom_n_chunks (dict): A dictionary of chromosome names and number of chunks.
        genome_chunk_length (int): Total number of chunks in the genome.
        total_chunk_length (int): Total number of chunks in the genome multiplied by number of cell types.
        preloaded_data (list): A list of preloaded data for windows.
        usage_counters (list): A list of usage counters for preloaded data.
        locks (list): A list of locks for preloaded data.
        reload_queue (Queue): A queue for reloading data.
        reload_thread (threading.Thread): A thread for reloading data.
        peaks_dict (dict): A dictionary of pandas dataframes for peaks data.
        insulation (pd.DataFrame): A pandas dataframe for insulation data.

        Note:
        This implementation features a preloading mechanism to speed up data loading.
        It preloads a fixed number of windows and generates samples from the preloaded data.
        When a window is used up, it reloads the data for the window in a separate thread.
        Note that a window is 4Mbp in size while a chunk in zarr is 2Mbp in size, so each window contains two consecutive chunks.

        Returns:
        tuple: A tuple containing the extracted sample track, peak sequence, and a dictionary with metadata
            about the extracted sample, including cell type ID, chromosome name, and positions.
        """
        self.sequence = DenseZarrIO(genome_seq_zarr)
        self.zarr_dirs = zarr_dirs
        self.insulation_paths = insulation_paths
        self.preload_count = preload_count
        self.samples_per_window = samples_per_window
        self._initialize_datasets()

    def __getitem__(self, index: int):
        usable_slot = np.where(np.array(self.usage_counters)
                               < self.samples_per_window)[0]
        while len(usable_slot) == 0:
            logging.info('Waiting for a slot to be available')
            # Wait for 0.5 seconds for a slot to be available
            time.sleep(0.5)
            usable_slot = np.where(
                np.array(self.usage_counters) < self.samples_per_window)[0]
        preload_index = np.random.choice(usable_slot)
        with self.locks[int(preload_index)]:
            # Access the preloaded data for the specific index
            window = self.preloaded_data[preload_index]

        sample = self._extract_sample_from_window(window)

        with self.locks[preload_index]:
            # Update the usage counter for the specific index
            self.usage_counters[preload_index] += 1
            if self.usage_counters[preload_index] >= self.samples_per_window:
                self._reload_data(preload_index)

        return sample

    def __len__(self):
        # Return the length of the dataset
        # Implement based on how you define the length of your dataset
        # Could be based on total windows, number of samples per window, etc.
        return self.total_chunk_length * self.samples_per_window

    def _initialize_datasets(self):
        self.zarr_dict = {cdz.data_key: cdz for zarr_dir in self.zarr_dirs for cdz in [
            CelltypeDenseZarrIO(zarr_dir)]}
        self.data_keys = list(self.zarr_dict.keys())
        self.peaks_dict = self._load_peaks()
        self.insulation = self._load_insulation(self.insulation_paths)

        self._calculate_metadata()
        self.preloaded_data = [self._load_window_data(random.randint(
            0, self.total_chunk_length)) for _ in range(self.preload_count)]
        self.usage_counters = np.zeros(self.preload_count, dtype=np.int32)
        self.locks = [threading.Lock() for _ in range(self.preload_count)]
        self._start_reload_thread()

    def _calculate_metadata(self):
        first_zarr = next(iter(self.zarr_dict.values()))
        self.n_celltypes = sum(
            zarr.n_celltypes for zarr in self.zarr_dict.values())
        self.chunk_size = first_zarr.chunk_size
        self.chrom_n_chunks = first_zarr.chrom_n_chunks
        self.genome_chunk_length = sum(
            n_chunks - 1 for n_chunks in self.chrom_n_chunks.values())
        self.total_chunk_length = self.genome_chunk_length * self.n_celltypes

    def _start_reload_thread(self):
        self.reload_queue = Queue()
        self.reload_thread = threading.Thread(
            target=self._process_reload_queue)
        self.reload_thread.start()

    def _process_reload_queue(self):
        while True:
            index = self.reload_queue.get()
            if index is None:
                break
            self._async_reload_data(index)
            self.reload_queue.task_done()

    def _reload_data(self, index):
        # Modify the usage counter and initiate reloading for the specific index
        self.reload_queue.put(index)

    def _preload_data(self):
        # Preload data
        # Load data for a fixed number of windows
        return [self._load_window_data(random.randint(0, self.total_chunk_length)) for _ in range(self.preload_count)]

    def _load_window_data(self, window_index):
        data_key, celltype_id = self._get_celltype_info(window_index)
        chr_name, chunk_idx, start, end = self._get_chromosome_info(
            window_index)

        celltype_peaks = self._query_peaks(celltype_id, chr_name, start, end)
        item_insulation = self._query_insulation(chr_name, start, end)

        track = self.zarr_dict[data_key].get_track(
            celltype_id, chr_name, start, end, sparse=True).T
        sequence = self.sequence.get_track(chr_name, start, end, sparse=False)

        peak_sequence = self._generate_peak_sequence(celltype_peaks, sequence, start)

        return window_index, chr_name, start, end, celltype_id, track, peak_sequence, item_insulation

    def _get_celltype_info(self, window_index):
        celltype_idx = window_index // self.genome_chunk_length
        data_key, celltype_id = self._get_celltype(celltype_idx)
        return data_key, celltype_id

    def _get_chromosome_info(self, window_index):
        chunk_idx = window_index % self.genome_chunk_length
        chr_name, chunk_idx = self._get_chr_chunk_idx(chunk_idx)
        start, end = self._get_start_end(chr_name, chunk_idx)
        return chr_name, chunk_idx, start, end

    def _query_peaks(self, celltype_id, chr_name, start, end):
        return self.peaks_dict[celltype_id].query(
            'Chromosome == @chr_name and Start >= @start and End <= @end')

    def _query_insulation(self, chr_name, start, end):
        return self.insulation.query(
            'Chromosome == @chr_name and Start >= @start and End <= @end')

    def _generate_peak_sequence(self, celltype_peaks, sequence, window_start):
        peak_sequence = np.zeros_like(sequence, dtype=np.int32)
        for start, end in celltype_peaks[['Start', 'End']].to_numpy():
            peak_sequence[start-window_start:end-window_start] = 1
        return csr_matrix(peak_sequence*sequence)

    def _async_reload_data(self, index):
        logging.info('Reloading data')
        # This method runs in a separate thread
        new_data = self._load_window_data(
            random.randint(0, self.total_chunk_length))
        # Update the preloaded data for the specific index
        self.preloaded_data[index] = new_data
        # reset the usage counter
        self.usage_counters[index] = 0

    def _extract_sample_from_window(self, window):
        """
        Extract a single sample from a preloaded window.

        This method selects a portion of the data within a preloaded 4Mbp window based on insulation data.
        It extracts a sample track and peak sequence from the window for further processing.

        Parameters:
        window (tuple): Contains preloaded data for a window, including window index, chromosome name,
                        start and end positions, cell type ID, track data, peak sequence, and insulation data.

        Returns:
        tuple: A tuple containing the extracted sample track, peak sequence, and a dictionary with metadata
            about the extracted sample, including cell type ID, chromosome name, and positions.

        Note:
        This implementation relies on the availability of insulation data. If insulation data is empty,
        it attempts to load data from another randomly selected window.
        """
        window_index, chr_name, start, end, celltype_id, track, peak_sequence, insulation = window
        if len(insulation) == 0:
            return self._handle_empty_insulation()

        i_start, i_end = self._insulation_sampler(insulation)
        i_start, i_end = self._adjust_indices_relative_to_window(
            i_start, i_end, start)

        sample_track = track[i_start:i_end]
        sample_peak_sequence = peak_sequence[i_start:i_end]

        sample_metadata = {
            'celltype_id': celltype_id, 'chr_name': chr_name,
            'start': start, 'end': end, 'i_start': i_start, 'i_end': i_end
        }

        return sample_track, sample_peak_sequence, sample_metadata

    def _handle_empty_insulation(self):
        """
        Handle cases where insulation data is empty.

        This method attempts to load data from another randomly selected window.

        Returns:
        tuple: Extracted sample data from a new window.
        """
        new_window = self._load_window_data(
            random.randint(0, self.total_chunk_length))
        return self._extract_sample_from_window(new_window)

    def _adjust_indices_relative_to_window(self, i_start, i_end, start):
        """
        Adjust insulation indices relative to the start of the window.

        Parameters:
        i_start (int): The start index of insulation.
        i_end (int): The end index of insulation.
        start (int): The start position of the window.

        Returns:
        tuple: Adjusted start and end indices.
        """
        return i_start - start, i_end - start

    def _insulation_sampler(self, insulation):
        """
        Sample insulation from the insulation dataframe
        """
        sample_index = np.random.randint(0, len(insulation))
        i_start, i_end = insulation.iloc[sample_index][['Start', 'End']]
        return i_start, i_end

    def _load_peaks(self):
        """
        Load peaks data which is a dictionary of pandas dataframe feather
        """
        logging.info('Loading peaks data')
        peaks_dict = {}
        for data_key, cdz in self.zarr_dict.items():
            for celltype_id in cdz.ids:
                peaks_dict[celltype_id] = cdz.get_peaks(
                    celltype_id, 'peaks_p0.01')

        return peaks_dict

    def _load_insulation(self, insulation_paths: list):
        """
        Load insulation data which is a list of pandas dataframe feather
        """
        logging.info('Loading insulation data')
        insulation_list = []
        for path in insulation_paths:
            insulation_list.append(pd.read_feather(path))

        return pd.concat(insulation_list).drop_duplicates(subset=['Chromosome', 'Start', 'End'])

    def _get_celltype(self, celltype_idx):
        """
        Get the data_key and celltype from the celltype index
        """
        for data_key, cdz in self.zarr_dict.items():
            if celltype_idx < cdz.n_celltypes:
                return data_key, cdz.ids[celltype_idx]
            else:
                celltype_idx -= cdz.n_celltypes
        raise ValueError(f'Celltype index {celltype_idx} is out of range')

    def _get_chr_chunk_idx(self, chunk_idx):
        """
        Get the chromosome name and chunk index from the chunk index
        """
        for chr_name, n_chunks in self.chrom_n_chunks.items():
            if chunk_idx < n_chunks-1:
                return chr_name, chunk_idx
            else:
                chunk_idx -= n_chunks-1
        raise ValueError(f'Chunk index {chunk_idx} is out of range')

    def _get_start_end(self, chr_name, chunk_idx):
        """
        Get the start and end position from the chunk index
        """
        start = chunk_idx * self.chunk_size
        end = start + 2 * self.chunk_size
        return start, end

    def close(self):
        # Call this method to cleanly shut down the thread
        self.reload_queue.put(None)
        self.reload_thread.join()


# %%
pretrain = PretrainDataset(['/pmglocal/xf2217/shendure_fetal/shendure_fetal_dense.zarr', 
                            '/pmglocal/xf2217/bingren_adult/bingren_adult_dense.zarr'], 
                           '/manitou/pmg/users/xf2217/get_model/data/hg38.zarr', [
                           '/manitou/pmg/users/xf2217/get_model/data/hg38_4DN_average_insulation.ctcf.longrange.feather', '/manitou/pmg/users/xf2217/get_model/data/hg38_4DN_average_insulation.ctcf.adjecent.feather'], preload_count=50, samples_per_window=50)
pretrain.__len__()
# %%
for i in tqdm(range(pretrain.__len__())):
    pretrain.__getitem__(1)

