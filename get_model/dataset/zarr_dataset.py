# %%
import logging
import os.path
import random
import sys
import threading
import time
import warnings
from glob import glob
from math import log
from posixpath import basename
from queue import Queue

import numpy as np
import pandas as pd
import zarr
from caesar.io.zarr_io import CelltypeDenseZarrIO, DenseZarrIO
from pyranges import PyRanges as pr
from scipy.sparse import csr_matrix, vstack
from torch.utils.data import Dataset
from tqdm import tqdm

from get_model.dataset.io import (generate_paths, get_hierachical_ctcf_pos,
                                  prepare_sequence_idx)
from get_model.dataset.splitter import cell_splitter, chromosome_splitter

logging.basicConfig(level=logging.INFO,
                    format='%(asctime)s - %(levelname)s - %(message)s')


# Suppress all deprecated warnings
warnings.filterwarnings("ignore", category=DeprecationWarning)

sys.path.append('/manitou/pmg/users/xf2217/get_model')

class PretrainDataset(Dataset):
    def __init__(self, zarr_dirs, genome_seq_zarr, insulation_paths, preload_count=50, samples_per_window=50, padding=50, mask_ratio=0.5):
        super().__init__()
        """
        Pretrain dataset for GET model.

        This dataset is used to train the GET model in a self-supervised manner.
        It loads data from a set of zarr files and generates samples for training.
        Each sample consists of a track and a peak sequence extracted from a 4Mbp window.
        The track is a 2D sparse array of shape (nucleotide,1) and the peak sequence is a 2D array of shape (nucleotide,4). Peak sequence is generated by multiplying the peak mask with the genomic sequence. Track is cell-type specific ATAC-seq insertion counts per nucleotide, without any normalization. Peak sequence is a one-hot encoding of DNA. Other metadata about the sample is also included in the sample as a dictionary.

        Parameters:
        zarr_dirs (list): A list of paths to zarr files.
        genome_seq_zarr (str): Path to the genome sequence zarr file.
        insulation_paths (list): A list of paths to insulation data.
        preload_count (int): Number of windows to preload.
        samples_per_window (int): Number of samples to generate from each window.

        Attributes:
        zarr_dirs (list): A list of paths to zarr files.
        genome_seq_zarr (str): Path to the genome sequence zarr file.
        insulation_paths (list): A list of paths to insulation data.
        preload_count (int): Number of windows to preload.
        samples_per_window (int): Number of samples to generate from each window.
        sequence (DenseZarrIO): An instance of DenseZarrIO for genome sequence.
        zarr_dict (dict): A dictionary of CelltypeDenseZarrIO instances for zarr files.
        data_keys (list): A list of data keys for zarr files.
        n_celltypes (int): Number of cell types.
        chunk_size (int): Chunk size.
        chrom_n_chunks (dict): A dictionary of chromosome names and number of chunks.
        genome_chunk_length (int): Total number of chunks in the genome.
        total_chunk_length (int): Total number of chunks in the genome multiplied by number of cell types.
        preloaded_data (list): A list of preloaded data for windows.
        usage_counters (list): A list of usage counters for preloaded data.
        locks (list): A list of locks for preloaded data.
        reload_queue (Queue): A queue for reloading data.
        reload_thread (threading.Thread): A thread for reloading data.
        peaks_dict (dict): A dictionary of pandas dataframes for peaks data.
        insulation (pd.DataFrame): A pandas dataframe for insulation data.

        Note:
        This implementation features a preloading mechanism to speed up data loading.
        It preloads a fixed number of windows and generates samples from the preloaded data.
        When a window is used up, it reloads the data for the window in a separate thread.
        Note that a window is 4Mbp in size while a chunk in zarr is 2Mbp in size, so each window contains two consecutive chunks.

        Returns:
        tuple: A tuple containing the extracted sample track, peak sequence, and a dictionary with metadata
            about the extracted sample, including cell type ID, chromosome name, and positions.
        """
        self.sequence = DenseZarrIO(genome_seq_zarr)
        # self.sequence.load_to_memory_dense()
        self.zarr_dirs = zarr_dirs
        self.insulation_paths = insulation_paths
        self.preload_count = preload_count
        self.samples_per_window = samples_per_window
        self.padding = padding
        self.mask_ratio = mask_ratio
        self._initialize_datasets()

    def __getitem__(self, index: int):
        try:
            return self._getitem(index)
        except Exception as e:
            logging.info(f'Error: {e}')

    def _getitem(self, index: int):

        while self.insulation_peak_counts.shape[0] == 0:
            if self.reload_queue.qsize() > 0:
                logging.info(
                    'Waiting for insulation_peak_counts to be available')
                # Wait for 0.5 seconds for a slot to be available
                time.sleep(0.5)
                continue
            else:
                self._preload_data()
                continue

        with self.insulation_lock:
            sample_key = self.insulation_peak_counts.iloc[0]['key']
            window_index, insulation_index = map(int, sample_key.split('_'))

        window_slot = self.preloaded_data_window_indices_mapping[window_index]
        usable_slot = np.where(np.array(self.usage_counters)
                               < self.samples_per_window)[0]
        while window_slot not in usable_slot:
            # logging.info('Waiting for a slot to be available')
            # Wait for 0.5 seconds for a slot to be available
            time.sleep(0.5)
            usable_slot = np.where(
                np.array(self.usage_counters) < self.samples_per_window)[0]

        # Retrieve preloaded data using window index

        with self.locks[window_slot]:
            window = self.preloaded_data[window_slot]

        # Extract the sample
        sample = self._extract_sample_from_window(window, insulation_index)

        # Update insulation_peak_counts to remove the current sample
        with self.insulation_lock:
            self.insulation_peak_counts = self.insulation_peak_counts.iloc[1:]

        # Update usage counter and possibly reload data
        with self.locks[window_slot]:
            self.usage_counters[window_slot] += 1
            if self.usage_counters[window_slot] >= self.samples_per_window:
                self._reload_data(window_slot)

        return sample

    def __len__(self):
        # Return the length of the dataset
        # Implement based on how you define the length of your dataset
        # Could be based on total windows, number of samples per window, etc.
        return self.total_chunk_length * self.samples_per_window

    def _initialize_datasets(self):
        self.zarr_dict = {cdz.data_key: cdz for zarr_dir in self.zarr_dirs for cdz in [
            CelltypeDenseZarrIO(zarr_dir)]}
        self.data_keys = list(self.zarr_dict.keys())
        self.peaks_dict = self._load_peaks()
        self.insulation = self._load_insulation(
            self.insulation_paths).sample(frac=0.1).reset_index(drop=True)

        self._calculate_metadata()
        self._preload_data()
        self._setup_locks()
        self._start_reload_thread()

    def _setup_locks(self):
        self.usage_counters = np.zeros(self.preload_count, dtype=np.int32)
        self.locks = [threading.Lock() for _ in range(self.preload_count)]
        self.insulation_lock = threading.Lock()

    def _load_window_data(self, window_index):
        data_key, celltype_id = self._get_celltype_info(window_index)
        chr_name, chunk_idx, start, end = self._get_chromosome_info(
            window_index)

        celltype_peaks = self._query_peaks(celltype_id, chr_name, start, end)
        item_insulation = self._query_insulation(chr_name, start, end)

        track = self.zarr_dict[data_key].get_track(
            celltype_id, chr_name, start, end, sparse=True).T
        sequence = self.sequence.get_track(chr_name, start, end, sparse=False)

        peak_sequence = self._generate_peak_sequence(
            celltype_peaks, sequence, start, end)
        item_insulation = item_insulation.reset_index(drop=True).reset_index()
        item_insulation['key'] = str(
            window_index) + '_' + item_insulation['index'].astype(str)
        celltype_peaks = celltype_peaks.reset_index(drop=True).reset_index()
        return window_index, chr_name, start, end, celltype_id, track, peak_sequence, item_insulation, celltype_peaks

    def _get_peak_count(self, item_insulation, celltype_peaks):
        df = pr(item_insulation).join(pr(celltype_peaks), suffix="_peak").df.groupby(
            'key').index_peak.count().reset_index()
        return df.set_index('key').to_dict()['index_peak']

    def _calculate_peak_num_per_sample(self):
        insulation_pool_peak_num = {}
        for _, _, _, _, _, _, _, item_insulation, celltype_peaks in self.preloaded_data:
            try:
                insulation_pool_peak_num.update(
                    self._get_peak_count(item_insulation, celltype_peaks))
            except:
                continue
        # Convert to DataFrame and sort
        insulation_pool_peak_num_df = pd.DataFrame.from_dict(
            insulation_pool_peak_num, orient='index').reset_index()
        insulation_pool_peak_num_df.columns = ['key', 'peak_num']
        insulation_pool_peak_num_df.sort_values('peak_num', inplace=True)
        return insulation_pool_peak_num_df.query('peak_num>3')

    def _calculate_metadata(self):
        first_zarr = next(iter(self.zarr_dict.values()))
        self.n_celltypes = sum(
            zarr.n_celltypes for zarr in self.zarr_dict.values())
        self.chunk_size = first_zarr.chunk_size
        self.chrom_n_chunks = first_zarr.chrom_n_chunks
        self.genome_chunk_length = sum(
            n_chunks - 1 for n_chunks in self.chrom_n_chunks.values())
        self.total_chunk_length = self.genome_chunk_length * self.n_celltypes

    def _start_reload_thread(self):
        self.reload_queue = Queue()
        self.reload_thread = threading.Thread(
            target=self._process_reload_queue)
        self.reload_thread.start()

    def _process_reload_queue(self):
        while True:
            index = self.reload_queue.get()
            if index is None:
                logging.info('Exiting reload thread')
                break
            self._async_reload_data(index)
            self.reload_queue.task_done()

    def _reload_data(self, index):
        # Modify the usage counter and initiate reloading for the specific index
        self.reload_queue.put(index)

    def _preload_data(self):
        # Preload data
        # Load data for a fixed number of windows
        self.preloaded_data = []
        self.preloaded_data_window_indices_mapping = {}
        for i in range(self.preload_count):
            window_index, chr_name, start, end, celltype_id, track, peak_sequence, item_insulation, celltype_peaks = self._load_window_data(
                random.randint(0, self.total_chunk_length))
            self.preloaded_data.append((window_index, chr_name, start, end,
                                       celltype_id, track, peak_sequence, item_insulation, celltype_peaks))
            self.preloaded_data_window_indices_mapping[window_index] = i
        # trigger the computation of peak_num_per_sample
        self.insulation_peak_counts = self._calculate_peak_num_per_sample()

    def _get_celltype_info(self, window_index):
        celltype_idx = window_index // self.genome_chunk_length
        data_key, celltype_id = self._get_celltype(celltype_idx)
        return data_key, celltype_id

    def _get_chromosome_info(self, window_index):
        chunk_idx = window_index % self.genome_chunk_length
        chr_name, chunk_idx = self._get_chr_chunk_idx(chunk_idx)
        start, end = self._get_start_end(chr_name, chunk_idx)
        return chr_name, chunk_idx, start, end

    def _query_peaks(self, celltype_id, chr_name, start, end):
        return self.peaks_dict[celltype_id].query(
            'Chromosome == @chr_name and Start >= @start and End <= @end')

    def _query_insulation(self, chr_name, start, end):
        return self.insulation.query(
            'Chromosome == @chr_name and Start >= @start and End <= @end')

    def _generate_peak_sequence(self, celltype_peaks, sequence, window_start, window_end):
        peak_sequence = np.zeros_like(sequence, dtype=np.int32)
        for start, end in celltype_peaks[['Start', 'End']].to_numpy():
            peak_sequence[start-window_start:end-window_start] = 1
        return csr_matrix(peak_sequence*sequence)

    def _async_reload_data(self, index):
        # This method runs in a separate thread
        logging.info(f'Async reloading data for slot {index}')
        new_data = self._load_window_data(
            random.randint(0, self.total_chunk_length))

        # Update the mapping
        new_window_index = new_data[0]

        # First remove the old mapping
        old_window_index = self.preloaded_data[index][0]
        del self.preloaded_data_window_indices_mapping[old_window_index]
        # Then add the new mapping
        self.preloaded_data_window_indices_mapping[new_window_index] = index

        # Update insulation_peak_counts to remove the current sample
        self.insulation_peak_counts = self._calculate_peak_num_per_sample().query(
            f'~(key.str.startswith("{str(old_window_index)}"))')
        # Update the preloaded data for the specific index
        self.preloaded_data[index] = new_data
        # reset the usage counter
        self.usage_counters = [0] * self.preload_count

    def _extract_sample_from_window(self, window, insulation_index):
        """
        Extract a single sample from a preloaded window.

        This method selects a portion of the data within a preloaded 4Mbp window based on insulation data.
        It extracts a sample track and peak sequence from the window for further processing.

        Parameters:
        window (tuple): Contains preloaded data for a window, including window index, chromosome name,
                        start and end positions, cell type ID, track data, peak sequence, and insulation data.

        Returns:
        tuple: A tuple containing the extracted sample track, peak sequence, and a dictionary with metadata
            about the extracted sample, including cell type ID, chromosome name, and positions.

        Note:
        This implementation relies on the availability of insulation data. If insulation data is empty,
        it attempts to load data from another randomly selected window.
        """
        window_index, chr_name, start, end, celltype_id, track, peak_sequence, insulation, celltype_peaks = window
        if len(insulation) == 0:
            raise ValueError('Empty insulation')
        i_start, i_end = self._insulation_sampler(insulation, insulation_index)
        celltype_peaks = celltype_peaks.query(
            'Start>@i_start and End<@i_end')[['Start', 'End']].to_numpy()
        if len(celltype_peaks) == 0:
            raise ValueError('No peaks in insulation region')
        wi_start, wi_end = self._adjust_indices_relative_to_window(
            i_start, i_end, start)
        celltype_peaks = celltype_peaks - i_start
        sample_track = track[wi_start:wi_end]
        sample_peak_sequence = peak_sequence[wi_start:wi_end]
        sample_peak_sequence = vstack(
            [sample_peak_sequence[start-self.padding:end+self.padding] for start, end in celltype_peaks])
        sample_track = vstack(
            [sample_track[start-self.padding:end+self.padding] for start, end in celltype_peaks])
        sample_metadata = {
            'celltype_id': celltype_id, 'chr_name': chr_name,
            'start': start, 'end': end, 'i_start': wi_start, 'i_end': wi_end, 'mask_ratio': self.mask_ratio
        }

        return sample_track, sample_peak_sequence, sample_metadata, celltype_peaks

    def _adjust_indices_relative_to_window(self, i_start, i_end, start):
        """
        Adjust insulation indices relative to the start of the window.

        Parameters:
        i_start (int): The start index of insulation.
        i_end (int): The end index of insulation.
        start (int): The start position of the window.

        Returns:
        tuple: Adjusted start and end indices.
        """
        return i_start - start, i_end - start

    def _insulation_sampler(self, insulation, sample_index=None):
        """
        Sample insulation from the insulation dataframe
        """
        if sample_index is None:
            sample_index = np.random.randint(0, len(insulation))
        i_start, i_end = insulation.iloc[sample_index][['Start', 'End']]
        return i_start, i_end

    def _load_peaks(self):
        """
        Load peaks data which is a dictionary of pandas dataframe feather
        """
        logging.info('Loading peaks data')
        peaks_dict = {}
        for data_key, cdz in self.zarr_dict.items():
            for celltype_id in cdz.ids:
                peaks_dict[celltype_id] = cdz.get_peaks(
                    celltype_id, 'peaks_p0.01')

        return peaks_dict

    def _load_insulation(self, insulation_paths: list):
        """
        Load insulation data which is a list of pandas dataframe feather
        """
        logging.info('Loading insulation data')
        insulation_list = []
        for path in insulation_paths:
            insulation_list.append(pd.read_feather(path))

        return pd.concat(insulation_list).drop_duplicates(subset=['Chromosome', 'Start', 'End'])

    def _get_celltype(self, celltype_idx):
        """
        Get the data_key and celltype from the celltype index
        """
        for data_key, cdz in self.zarr_dict.items():
            if celltype_idx < cdz.n_celltypes:
                return data_key, cdz.ids[celltype_idx]
            else:
                celltype_idx -= cdz.n_celltypes
        raise ValueError(f'Celltype index {celltype_idx} is out of range')

    def _get_chr_chunk_idx(self, chunk_idx):
        """
        Get the chromosome name and chunk index from the chunk index
        """
        for chr_name, n_chunks in self.chrom_n_chunks.items():
            if chunk_idx < n_chunks-1:
                return chr_name, chunk_idx
            else:
                chunk_idx -= n_chunks-1
        raise ValueError(f'Chunk index {chunk_idx} is out of range')

    def _get_start_end(self, chr_name, chunk_idx):
        """
        Get the start and end position from the chunk index
        """
        start = chunk_idx * self.chunk_size
        end = start + 2 * self.chunk_size
        return start, end

    def close(self):
        # Call this method to cleanly shut down the thread
        self.reload_queue.put(None)
        self.reload_thread.join()
        # clear all the locks
        for lock in self.locks:
            lock.acquire()
            lock.release()


# %%
