model:
  _target_: get_model.model.model_refactored.GETPretrainMaxNorm
  cfg:
    num_regions: 10
    num_motif: 637
    embed_dim: 768
    num_layers: 12
    num_heads: 12
    dropout: 0.1
    output_dim: 800
    flash_attn: false
    pool_method: 'mean'
    motif_scanner:
      num_motif: ${model.cfg.num_motif}
      include_reverse_complement: true
      bidirectional_except_ctcf: true
      motif_prior: true
      learnable: false
    atac_attention:
      motif_dim: 639 # 637 motifs + 2 ctcf
      pool_method: 'mean'
      atac_kernel_num: 161
      atac_kernel_size: 3
      joint_kernel_num: 161
      joint_kernel_size: 3
      binary_atac: false
      final_bn: false
    region_embed:
      num_regions: ${model.cfg.num_regions}
      num_features: 800 # 639 + 161
      embed_dim: ${model.cfg.embed_dim}
    encoder:
      num_heads: ${model.cfg.num_heads}
      embed_dim: ${model.cfg.embed_dim}
      num_layers: ${model.cfg.num_layers}
      drop_path_rate: ${model.cfg.dropout}
      drop_rate: ${model.cfg.dropout}
      attn_drop_rate: ${model.cfg.dropout}
      use_mean_pooling: false
      flash_attn: ${model.cfg.flash_attn}
    head_mask:
      in_features: ${model.cfg.embed_dim}
      out_features: ${model.cfg.output_dim}
    mask_token:
      embed_dim: ${model.cfg.embed_dim}
      std: 0.02
    loss:
      components:
        masked: 
          _target_: torch.nn.MSELoss
          reduction: 'mean'
      weights: 
        masked: 1.0
    metrics:
      masked: ['pearson', 'spearman', 'mse']
      
dataset:
  data_set: "Expression_Finetune_Fetal"
  eval_data_set: "Expression_Finetune_Fetal.fetal_eval"
  data_path: "/pmglocal/xf2217/get_data/"
  batch_size: 16
  num_workers: 16
  n_peaks_lower_bound: 5
  n_peaks_upper_bound: 10
  max_peak_length: 5000
  center_expand_target: 500
  use_insulation: false
  preload_count: 10
  random_shift_peak: 10
  pin_mem: true
  peak_name: "peaks_q0.01_tissue_open_exp"
  negative_peak_name: null
  n_packs: 1
  leave_out_celltypes: "Astrocyte"
  leave_out_chromosomes: "chr4,chr14"
  dataset_size: 4096
  additional_peak_columns:  ['Expression_positive', 'Expression_negative', 'aTPM', 'TSS']
  padding: 0
  mask_ratio: 0.5
  insulation_subsample_ratio: 1
  negative_peak_ratio: 0
  peak_inactivation: null
  non_redundant: false
  filter_by_min_depth: false
  hic_path: null

training:
  num_devices: 1
  save_ckpt_freq: 10
  epochs: 2
  warmup_epochs: 1
  accumulate_grad_batches: 1
  clip_grad: null
  use_fp16: true
  output_dir: "/pmglocal/xf2217/output"

optimizer:
  lr: 0.001
  min_lr: 0.0001
  weight_decay: 0.05
  opt: 'adamw'
  opt_eps: 1e-8
  opt_betas: [0.9, 0.95]

wandb:
  project_name: "pretrain"
  run_name: "experiment_1"

finetune:  
  checkpoint: null
  model_prefix: "model."
  patterns_to_freeze: ["motif_scanner"]