defaults:
  - base_ref_region_config
  - model/GETRegionFinetune@_here_
  - machine/manitou_alb2281
  - finetune/v1_finetune@finetune
  - dataset/finetune_k562_cage@dataset
  - _self_

assembly: "hg38"

task:
  layer_names: []
  test_mode: "skip"

training:
  save_ckpt_freq: 10
  epochs: 100
  warmup_epochs: 1
  accumulate_grad_batches: 1
  clip_grad: null
  use_fp16: true

dataset:
  quantitative_atac: true
  sampling_step: 450
  mask_ratio: 0


optimizer:
  lr: 0.0001
  min_lr: 0.0001
  weight_decay: 0.05
  opt: "adamw"
  opt_eps: 1e-8
  opt_betas: [0.9, 0.95]

run:
  project_name: "finetune_k562_cage_lora"
  run_name: "finetune_k562.encode_hg38atac.ENCFF128WZG_cage.watac_from_scratch"

finetune:
  pretrain_checkpoint: false
  strict: true
  use_lora: true
  layers_with_lora: ['region_embed', 'encoder']
  checkpoint: null
  patterns_to_freeze: []
  model_key: 'model'

eval_tss: true
log_image: false
