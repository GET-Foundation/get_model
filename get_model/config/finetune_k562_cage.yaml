defaults:
  - base_config
  - model/GETFinetune@_here_
  - machine/manitou_alb2281
  - dataset/finetune_k562_cage@dataset
  - _self_

assembly: "hg38"

task:
  layer_names: ["atac_attention"]
  test_mode: "skip"
  gene_list: "PPIF"

training:
  save_ckpt_freq: 10
  epochs: 100
  warmup_epochs: 1
  accumulate_grad_batches: 1
  clip_grad: null
  use_fp16: true

optimizer:
  lr: 0.0001
  min_lr: 0.0001
  weight_decay: 0.05
  opt: "adamw"
  opt_eps: 1e-8
  opt_betas: [0.9, 0.95]

wandb:
  project_name: "finetune_k562_cage"
  run_name: "finetune_k562.encode_hg38atac.ENCFF128WZG_cage.max"

finetune:
  pretrain_checkpoint: false
  strict: true
  checkpoint: "/burg/pmg/users/xf2217/get_checkpoints/Astrocytes_natac/checkpoint-best.pth"
  use_lora: true
  layers_with_lora: ['region_embed', 'head_exp', 'encoder']
  patterns_to_freeze: []
