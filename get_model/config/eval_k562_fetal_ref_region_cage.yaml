defaults:
  - base_ref_region_config
  - model/GETRegionFinetune@_here_
  - machine/pc
  - finetune/v1_pretrain@finetune
  - dataset/k562_cage@dataset
  - _self_

assembly: "hg38"

task:
  layer_names: []
  test_mode: "interpret"

training:
  save_ckpt_freq: 1
  epochs: 100
  warmup_epochs: 1
  accumulate_grad_batches: 1
  clip_grad: null
  use_fp16: false

dataset:
  quantitative_atac: false
  sampling_step: 450
  mask_ratio: 0

optimizer:
  lr: 0.0001
  min_lr: 0.000001
  weight_decay: 0.05
  opt: "adamw"
  opt_eps: 1e-8
  opt_betas: [0.9, 0.999]

wandb:
  project_name: "GETRegionFinetune_k562_cage"
  run_name: "BATAC_LoRA_from_BATAC_pretrain"

finetune:
  pretrain_checkpoint: true
  strict: false
  use_lora: true
  layers_with_lora: ['region_embed', 'encoder']
  checkpoint: "/home/xf2217/Projects/get_checkpoints/new_output_e800_r200_mask0.5_adult_natac_human_bingren_shendure/checkpoint-799.pth"
  patterns_to_freeze: []
  model_key: 'model'


eval_tss: true
log_image: true
