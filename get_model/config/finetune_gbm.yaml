defaults:
  - base_ref_region_config
  - model/GETRegionFinetune@_here_
  - machine/manitou_alb2281
  - finetune/v1_finetune@finetune
  - dataset/finetune_gbm@dataset
  - _self_

assembly: "hg38"

task:
  layer_names: []
  test_mode: "skip"

training:
  save_ckpt_freq: 10
  epochs: 100
  warmup_epochs: 1
  accumulate_grad_batches: 1
  clip_grad: null
  use_fp16: true

dataset:
  quantitative_atac: true
  sampling_step: 450
  mask_ratio: 0


optimizer:
  lr: 0.0001
  min_lr: 0.0001
  weight_decay: 0.05
  opt: "adamw"
  opt_eps: 1e-8
  opt_betas: [0.9, 0.95]

wandb:
  project_name: "finetune_gbm_lora"
  run_name: "finetune_Tumor.htan_gbm.C3L-03405_CPT0224600013_snATAC_GBM_Tumor.2048_lora_watac"

finetune:
  pretrain_checkpoint: false
  strict: false
  use_lora: true
  layers_with_lora: ['region_embed', 'encoder']
  checkpoint: "/pmglocal/alb2281/get/get_ckpts/watac_checkpoint_best.pth"
  patterns_to_freeze: []
  model_key: 'model'

eval_tss: true
log_image: false