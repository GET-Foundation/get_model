{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Training a GET Model for ATAC-seq Prediction\n",
    "\n",
    "\n",
    "\n",
    " This tutorial demonstrates how to train a GET model to predict ATAC-seq peaks using motif information. We'll cover:\n",
    "\n",
    " 1. Loading and configuring the model\n",
    "\n",
    " 2. Training without a pretrained checkpoint\n",
    "\n",
    " 3. Training with a pretrained checkpoint\n",
    "\n",
    " 4. Comparing the results\n",
    "\n",
    "\n",
    "\n",
    " ## Setup\n",
    "\n",
    " First, let's import the necessary modules and set up our configuration.\n",
    " \n",
    " Note:\n",
    " If you run from a Mac, make sure you use the jupyter notebook rather than the VSCode interactive python editor as the later seems to have issue with multiple workers.\n",
    " If you run from Linux, both should work fine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "from get_model.config.config import load_config, pretty_print_config\n",
    "from get_model.run_region import run_zarr as run\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Configuration\n",
    "\n",
    "\n",
    "\n",
    " We'll start by loading a predefined configuration and customizing it for our needs.\n",
    "\n",
    " The base configuration is in `get_model/config/finetune_tutorial.yaml`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "cfg = load_config('finetune_tutorial') # load the predefined finetune tutorial config\n",
    "cfg.run.run_name='predict_atac' # this is a unique name for this run\n",
    "cfg.dataset.zarr_path = \"./output.zarr\" # the tutorial data which contains astrocyte atac & rna\n",
    "cfg.dataset.celltypes = 'astrocyte' # the celltypes you want to finetune\n",
    "cfg.dataset.leave_out_chromosomes = 'chr10,chr11'\n",
    "cfg.run.use_wandb=True # this is a logging system, you can turn it off by setting it to False\n",
    "cfg.training.epochs = 5 # this is the number of epochs you want to train for\n",
    "cfg.training.val_check_interval = 1.0 # validation check every epochs; this is for mac because the evaluation step is slow on it somehow..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Switch machine to mac\n",
    "\n",
    " One can define machine config in a yaml file, and load it here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run:\n",
      "  project_name: finetune_tutorial\n",
      "  run_name: predict_atac\n",
      "  use_wandb: true\n",
      "type: region\n",
      "stage: fit\n",
      "assembly: hg38\n",
      "eval_tss: true\n",
      "log_image: true\n",
      "model:\n",
      "  _target_: get_model.model.model.GETRegionFinetune\n",
      "  cfg:\n",
      "    num_regions: 900\n",
      "    num_motif: 283\n",
      "    embed_dim: 768\n",
      "    num_layers: 12\n",
      "    num_heads: 12\n",
      "    dropout: 0.1\n",
      "    output_dim: 2\n",
      "    flash_attn: false\n",
      "    pool_method: mean\n",
      "    region_embed:\n",
      "      num_regions: ${model.cfg.num_regions}\n",
      "      num_features: ${model.cfg.num_motif}\n",
      "      embed_dim: ${model.cfg.embed_dim}\n",
      "    encoder:\n",
      "      num_heads: ${model.cfg.num_heads}\n",
      "      embed_dim: ${model.cfg.embed_dim}\n",
      "      num_layers: ${model.cfg.num_layers}\n",
      "      drop_path_rate: ${model.cfg.dropout}\n",
      "      drop_rate: 0\n",
      "      attn_drop_rate: 0\n",
      "      use_mean_pooling: false\n",
      "      flash_attn: ${model.cfg.flash_attn}\n",
      "    head_exp:\n",
      "      embed_dim: ${model.cfg.embed_dim}\n",
      "      output_dim: ${model.cfg.output_dim}\n",
      "      use_atac: false\n",
      "    mask_token:\n",
      "      embed_dim: ${model.cfg.embed_dim}\n",
      "      std: 0.02\n",
      "    loss:\n",
      "      components:\n",
      "        exp:\n",
      "          _target_: torch.nn.PoissonNLLLoss\n",
      "          reduction: mean\n",
      "          log_input: false\n",
      "      weights:\n",
      "        exp: 1.0\n",
      "    metrics:\n",
      "      components:\n",
      "        exp:\n",
      "        - pearson\n",
      "        - spearman\n",
      "        - r2\n",
      "machine:\n",
      "  codebase: /Users/xf2217/Repos/get_model/\n",
      "  data_path: /Users/xf2217/Repos/get_model/\n",
      "  output_dir: /Users/xf2217/Downloads\n",
      "  num_devices: 1\n",
      "  num_workers: 4\n",
      "  batch_size: 2\n",
      "  fasta_path: ???\n",
      "dataset:\n",
      "  zarr_path: ./output.zarr\n",
      "  celltypes: astrocyte\n",
      "  transform: null\n",
      "  quantitative_atac: true\n",
      "  sampling_step: 100\n",
      "  num_region_per_sample: 200\n",
      "  leave_out_chromosomes: chr10,chr11\n",
      "  leave_out_celltypes: null\n",
      "  mask_ratio: 0.0\n",
      "training:\n",
      "  save_ckpt_freq: 1\n",
      "  epochs: 5\n",
      "  warmup_epochs: 1\n",
      "  accumulate_grad_batches: 1\n",
      "  clip_grad: null\n",
      "  use_fp16: false\n",
      "  log_every_n_steps: 25\n",
      "  val_check_interval: 1.0\n",
      "  add_lr_monitor: false\n",
      "optimizer:\n",
      "  lr: 0.0001\n",
      "  min_lr: 0.0001\n",
      "  weight_decay: 0.05\n",
      "  opt: adamw\n",
      "  opt_eps: 1.0e-08\n",
      "  opt_betas:\n",
      "  - 0.9\n",
      "  - 0.999\n",
      "finetune:\n",
      "  resume_ckpt: null\n",
      "  pretrain_checkpoint: false\n",
      "  checkpoint: /home/xf2217/Projects/get_checkpoints/Astrocytes/checkpoint-best.pth\n",
      "  strict: true\n",
      "  model_key: model\n",
      "  use_lora: false\n",
      "  lora_checkpoint: null\n",
      "  rename_config:\n",
      "    blocks.: encoder.blocks.\n",
      "    fc_norm.: encoder.norm.\n",
      "    encoder.head.: head_mask.\n",
      "    encoder.region_embed: region_embed\n",
      "    region_embed.proj.: region_embed.embed.\n",
      "    encoder.cls_token: cls_token\n",
      "    head.: head_exp.head.\n",
      "  layers_with_lora:\n",
      "  - region_embed\n",
      "  - encoder\n",
      "  - head_exp\n",
      "  patterns_to_freeze: []\n",
      "  patterns_to_drop: []\n",
      "  additional_checkpoints: []\n",
      "task:\n",
      "  test_mode: interpret\n",
      "  gene_list: MYC,SOX10,SOX2,RET\n",
      "  layer_names:\n",
      "  - region_embed\n",
      "  mutations: null\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "from get_model.config.config import MachineConfig\n",
    "\n",
    "cfg.machine = MachineConfig(**load_config('machine/mac').machine)\n",
    "# Note that you can also create a new yaml file replacing the finetune_tutorial.yaml\n",
    "# or change parameters here directly\n",
    "cfg.machine.batch_size = 2\n",
    "pretty_print_config(cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Model Selection\n",
    "\n",
    "\n",
    "\n",
    " We'll use the GETRegionFinetuneATAC model, which is designed to use motif information to predict the ATAC values\n",
    "\n",
    "\n",
    "\n",
    " This model is particularly useful for understanding the relationship between motifs and chromatin accessibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "# Switch model to finetune ATAC model\n",
    "cfg.model = load_config('model/GETRegionFinetuneATAC').model.model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Training Without Pretraining\n",
    "\n",
    "\n",
    "\n",
    " First, let's train the model from scratch (without using a pretrained checkpoint).\n",
    "\n",
    " This will give us a baseline for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xf2217/Softwares/.micromamba/envs/get/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: Metric `SpearmanCorrcoef` will save all targets and predictions in the buffer. For large datasets, this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)  # noqa: B028\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model = GETRegionFinetuneATAC(\n",
      "  (loss): GETLoss()\n",
      "  (metrics): RegressionMetrics(\n",
      "    (metrics): ModuleDict(\n",
      "      (atpm): ModuleDict(\n",
      "        (pearson): PearsonCorrCoef()\n",
      "        (spearman): SpearmanCorrCoef()\n",
      "        (r2): R2Score()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (region_embed): RegionEmbed(\n",
      "    (embed): Linear(in_features=283, out_features=768, bias=True)\n",
      "  )\n",
      "  (encoder): GETTransformer(\n",
      "    (blocks): ModuleList(\n",
      "      (0): Block(\n",
      "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=768, out_features=2304, bias=False)\n",
      "          (attn_drop): Dropout(p=0, inplace=False)\n",
      "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (proj_drop): Dropout(p=0, inplace=False)\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (drop1): Dropout(p=0, inplace=False)\n",
      "          (drop2): Dropout(p=0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (1): Block(\n",
      "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=768, out_features=2304, bias=False)\n",
      "          (attn_drop): Dropout(p=0, inplace=False)\n",
      "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (proj_drop): Dropout(p=0, inplace=False)\n",
      "        )\n",
      "        (drop_path): DropPath(drop_prob=0.009)\n",
      "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (drop1): Dropout(p=0, inplace=False)\n",
      "          (drop2): Dropout(p=0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (2): Block(\n",
      "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=768, out_features=2304, bias=False)\n",
      "          (attn_drop): Dropout(p=0, inplace=False)\n",
      "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (proj_drop): Dropout(p=0, inplace=False)\n",
      "        )\n",
      "        (drop_path): DropPath(drop_prob=0.018)\n",
      "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (drop1): Dropout(p=0, inplace=False)\n",
      "          (drop2): Dropout(p=0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (3): Block(\n",
      "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=768, out_features=2304, bias=False)\n",
      "          (attn_drop): Dropout(p=0, inplace=False)\n",
      "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (proj_drop): Dropout(p=0, inplace=False)\n",
      "        )\n",
      "        (drop_path): DropPath(drop_prob=0.027)\n",
      "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (drop1): Dropout(p=0, inplace=False)\n",
      "          (drop2): Dropout(p=0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (4): Block(\n",
      "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=768, out_features=2304, bias=False)\n",
      "          (attn_drop): Dropout(p=0, inplace=False)\n",
      "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (proj_drop): Dropout(p=0, inplace=False)\n",
      "        )\n",
      "        (drop_path): DropPath(drop_prob=0.036)\n",
      "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (drop1): Dropout(p=0, inplace=False)\n",
      "          (drop2): Dropout(p=0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (5): Block(\n",
      "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=768, out_features=2304, bias=False)\n",
      "          (attn_drop): Dropout(p=0, inplace=False)\n",
      "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (proj_drop): Dropout(p=0, inplace=False)\n",
      "        )\n",
      "        (drop_path): DropPath(drop_prob=0.045)\n",
      "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (drop1): Dropout(p=0, inplace=False)\n",
      "          (drop2): Dropout(p=0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (6): Block(\n",
      "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=768, out_features=2304, bias=False)\n",
      "          (attn_drop): Dropout(p=0, inplace=False)\n",
      "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (proj_drop): Dropout(p=0, inplace=False)\n",
      "        )\n",
      "        (drop_path): DropPath(drop_prob=0.055)\n",
      "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (drop1): Dropout(p=0, inplace=False)\n",
      "          (drop2): Dropout(p=0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (7): Block(\n",
      "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=768, out_features=2304, bias=False)\n",
      "          (attn_drop): Dropout(p=0, inplace=False)\n",
      "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (proj_drop): Dropout(p=0, inplace=False)\n",
      "        )\n",
      "        (drop_path): DropPath(drop_prob=0.064)\n",
      "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (drop1): Dropout(p=0, inplace=False)\n",
      "          (drop2): Dropout(p=0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (8): Block(\n",
      "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=768, out_features=2304, bias=False)\n",
      "          (attn_drop): Dropout(p=0, inplace=False)\n",
      "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (proj_drop): Dropout(p=0, inplace=False)\n",
      "        )\n",
      "        (drop_path): DropPath(drop_prob=0.073)\n",
      "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (drop1): Dropout(p=0, inplace=False)\n",
      "          (drop2): Dropout(p=0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (9): Block(\n",
      "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=768, out_features=2304, bias=False)\n",
      "          (attn_drop): Dropout(p=0, inplace=False)\n",
      "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (proj_drop): Dropout(p=0, inplace=False)\n",
      "        )\n",
      "        (drop_path): DropPath(drop_prob=0.082)\n",
      "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (drop1): Dropout(p=0, inplace=False)\n",
      "          (drop2): Dropout(p=0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (10): Block(\n",
      "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=768, out_features=2304, bias=False)\n",
      "          (attn_drop): Dropout(p=0, inplace=False)\n",
      "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (proj_drop): Dropout(p=0, inplace=False)\n",
      "        )\n",
      "        (drop_path): DropPath(drop_prob=0.091)\n",
      "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (drop1): Dropout(p=0, inplace=False)\n",
      "          (drop2): Dropout(p=0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (11): Block(\n",
      "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=768, out_features=2304, bias=False)\n",
      "          (attn_drop): Dropout(p=0, inplace=False)\n",
      "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (proj_drop): Dropout(p=0, inplace=False)\n",
      "        )\n",
      "        (drop_path): DropPath(drop_prob=0.100)\n",
      "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (drop1): Dropout(p=0, inplace=False)\n",
      "          (drop2): Dropout(p=0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "  )\n",
      "  (head_exp): ExpressionHead(\n",
      "    (head): Linear(in_features=768, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "run:\n",
      "  project_name: finetune_tutorial\n",
      "  run_name: predict_atac\n",
      "  use_wandb: true\n",
      "type: region\n",
      "stage: fit\n",
      "assembly: hg38\n",
      "eval_tss: true\n",
      "log_image: true\n",
      "model:\n",
      "  _target_: get_model.model.model.GETRegionFinetuneATAC\n",
      "  cfg:\n",
      "    num_regions: 200\n",
      "    num_motif: 283\n",
      "    embed_dim: 768\n",
      "    num_layers: 12\n",
      "    num_heads: 12\n",
      "    dropout: 0.1\n",
      "    output_dim: 1\n",
      "    flash_attn: false\n",
      "    pool_method: mean\n",
      "    region_embed:\n",
      "      num_regions: ${model.cfg.num_regions}\n",
      "      num_features: ${model.cfg.num_motif}\n",
      "      embed_dim: ${model.cfg.embed_dim}\n",
      "    encoder:\n",
      "      num_heads: ${model.cfg.num_heads}\n",
      "      embed_dim: ${model.cfg.embed_dim}\n",
      "      num_layers: ${model.cfg.num_layers}\n",
      "      drop_path_rate: ${model.cfg.dropout}\n",
      "      drop_rate: 0\n",
      "      attn_drop_rate: 0\n",
      "      use_mean_pooling: false\n",
      "      flash_attn: ${model.cfg.flash_attn}\n",
      "    head_exp:\n",
      "      embed_dim: ${model.cfg.embed_dim}\n",
      "      output_dim: 1\n",
      "      use_atac: false\n",
      "    mask_token:\n",
      "      embed_dim: ${model.cfg.embed_dim}\n",
      "      std: 0.02\n",
      "    loss:\n",
      "      components:\n",
      "        atpm:\n",
      "          _target_: torch.nn.PoissonNLLLoss\n",
      "          reduction: mean\n",
      "          log_input: false\n",
      "      weights:\n",
      "        atpm: 1.0\n",
      "    metrics:\n",
      "      components:\n",
      "        atpm:\n",
      "        - pearson\n",
      "        - spearman\n",
      "        - r2\n",
      "machine:\n",
      "  codebase: /Users/xf2217/Repos/get_model/\n",
      "  data_path: /Users/xf2217/Repos/get_model/\n",
      "  output_dir: /Users/xf2217/Downloads\n",
      "  num_devices: 1\n",
      "  num_workers: 4\n",
      "  batch_size: 2\n",
      "  fasta_path: ???\n",
      "dataset:\n",
      "  zarr_path: ./output.zarr\n",
      "  celltypes: astrocyte\n",
      "  transform: null\n",
      "  quantitative_atac: true\n",
      "  sampling_step: 100\n",
      "  num_region_per_sample: 200\n",
      "  leave_out_chromosomes: chr10,chr11\n",
      "  leave_out_celltypes: null\n",
      "  mask_ratio: 0.0\n",
      "training:\n",
      "  save_ckpt_freq: 1\n",
      "  epochs: 5\n",
      "  warmup_epochs: 1\n",
      "  accumulate_grad_batches: 1\n",
      "  clip_grad: null\n",
      "  use_fp16: false\n",
      "  log_every_n_steps: 25\n",
      "  val_check_interval: 1.0\n",
      "  add_lr_monitor: false\n",
      "optimizer:\n",
      "  lr: 0.0001\n",
      "  min_lr: 0.0001\n",
      "  weight_decay: 0.05\n",
      "  opt: adamw\n",
      "  opt_eps: 1.0e-08\n",
      "  opt_betas:\n",
      "  - 0.9\n",
      "  - 0.999\n",
      "finetune:\n",
      "  resume_ckpt: null\n",
      "  pretrain_checkpoint: false\n",
      "  checkpoint: null\n",
      "  strict: true\n",
      "  model_key: model\n",
      "  use_lora: false\n",
      "  lora_checkpoint: null\n",
      "  rename_config:\n",
      "    blocks.: encoder.blocks.\n",
      "    fc_norm.: encoder.norm.\n",
      "    encoder.head.: head_mask.\n",
      "    encoder.region_embed: region_embed\n",
      "    region_embed.proj.: region_embed.embed.\n",
      "    encoder.cls_token: cls_token\n",
      "    head.: head_exp.head.\n",
      "  layers_with_lora:\n",
      "  - region_embed\n",
      "  - encoder\n",
      "  - head_exp\n",
      "  patterns_to_freeze: []\n",
      "  patterns_to_drop: []\n",
      "  additional_checkpoints: []\n",
      "task:\n",
      "  test_mode: interpret\n",
      "  gene_list: MYC,SOX10,SOX2,RET\n",
      "  layer_names:\n",
      "  - region_embed\n",
      "  mutations: null\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mxf2217\u001b[0m (\u001b[33mget-v3\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/xf2217/Downloads/finetune_tutorial/predict_atac/wandb/run-20250102_231256-bvk25s3s</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/get-v3/finetune_tutorial/runs/bvk25s3s' target=\"_blank\">predict_atac</a></strong> to <a href='https://wandb.ai/get-v3/finetune_tutorial' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/get-v3/finetune_tutorial' target=\"_blank\">https://wandb.ai/get-v3/finetune_tutorial</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/get-v3/finetune_tutorial/runs/bvk25s3s' target=\"_blank\">https://wandb.ai/get-v3/finetune_tutorial/runs/bvk25s3s</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  9.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leave out chromosomes: ['chr10', 'chr11']\n",
      "Input chromosomes: ['chr1', 'chr2', 'chr3', 'chr4', 'chr4_GL000008v2_random', 'chr5', 'chr6', 'chr7', 'chr7_KI270803v1_alt', 'chr8', 'chr9', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chr22_KI270879v1_alt', 'chrX']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 71.13it/s]\n",
      "/Users/xf2217/Softwares/.micromamba/envs/get/lib/python3.10/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /Users/xf2217/Downloads/finetune_tutorial/predict_atac/checkpoints exists and is not empty.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leave out chromosomes: ['chr10', 'chr11']\n",
      "Input chromosomes: ['chr10', 'chr11']\n",
      "Assigned values = [0.023757264018058777, 0.03167635202407837, 0.04223513603210449, 0.056313514709472656, 0.07508468627929688, 0.1001129150390625, 0.13348388671875, 0.177978515625, 0.2373046875, 0.31640625, 0.421875, 0.5625, 0.75, 1.0]\n",
      "Skip weight decay list:  {'cls_token', 'pos_embed'}\n",
      "Param groups = {\n",
      "  \"layer_0_no_decay\": {\n",
      "    \"weight_decay\": 0.0,\n",
      "    \"params\": [\n",
      "      \"cls_token\",\n",
      "      \"region_embed.embed.bias\"\n",
      "    ],\n",
      "    \"lr_scale\": 0.023757264018058777\n",
      "  },\n",
      "  \"layer_0_decay\": {\n",
      "    \"weight_decay\": 0.05,\n",
      "    \"params\": [\n",
      "      \"region_embed.embed.weight\"\n",
      "    ],\n",
      "    \"lr_scale\": 0.023757264018058777\n",
      "  },\n",
      "  \"layer_1_no_decay\": {\n",
      "    \"weight_decay\": 0.0,\n",
      "    \"params\": [\n",
      "      \"encoder.blocks.0.norm1.weight\",\n",
      "      \"encoder.blocks.0.norm1.bias\",\n",
      "      \"encoder.blocks.0.attn.q_bias\",\n",
      "      \"encoder.blocks.0.attn.v_bias\",\n",
      "      \"encoder.blocks.0.attn.proj.bias\",\n",
      "      \"encoder.blocks.0.norm2.weight\",\n",
      "      \"encoder.blocks.0.norm2.bias\",\n",
      "      \"encoder.blocks.0.mlp.fc1.bias\",\n",
      "      \"encoder.blocks.0.mlp.fc2.bias\"\n",
      "    ],\n",
      "    \"lr_scale\": 0.03167635202407837\n",
      "  },\n",
      "  \"layer_1_decay\": {\n",
      "    \"weight_decay\": 0.05,\n",
      "    \"params\": [\n",
      "      \"encoder.blocks.0.attn.qkv.weight\",\n",
      "      \"encoder.blocks.0.attn.proj.weight\",\n",
      "      \"encoder.blocks.0.mlp.fc1.weight\",\n",
      "      \"encoder.blocks.0.mlp.fc2.weight\"\n",
      "    ],\n",
      "    \"lr_scale\": 0.03167635202407837\n",
      "  },\n",
      "  \"layer_2_no_decay\": {\n",
      "    \"weight_decay\": 0.0,\n",
      "    \"params\": [\n",
      "      \"encoder.blocks.1.norm1.weight\",\n",
      "      \"encoder.blocks.1.norm1.bias\",\n",
      "      \"encoder.blocks.1.attn.q_bias\",\n",
      "      \"encoder.blocks.1.attn.v_bias\",\n",
      "      \"encoder.blocks.1.attn.proj.bias\",\n",
      "      \"encoder.blocks.1.norm2.weight\",\n",
      "      \"encoder.blocks.1.norm2.bias\",\n",
      "      \"encoder.blocks.1.mlp.fc1.bias\",\n",
      "      \"encoder.blocks.1.mlp.fc2.bias\"\n",
      "    ],\n",
      "    \"lr_scale\": 0.04223513603210449\n",
      "  },\n",
      "  \"layer_2_decay\": {\n",
      "    \"weight_decay\": 0.05,\n",
      "    \"params\": [\n",
      "      \"encoder.blocks.1.attn.qkv.weight\",\n",
      "      \"encoder.blocks.1.attn.proj.weight\",\n",
      "      \"encoder.blocks.1.mlp.fc1.weight\",\n",
      "      \"encoder.blocks.1.mlp.fc2.weight\"\n",
      "    ],\n",
      "    \"lr_scale\": 0.04223513603210449\n",
      "  },\n",
      "  \"layer_3_no_decay\": {\n",
      "    \"weight_decay\": 0.0,\n",
      "    \"params\": [\n",
      "      \"encoder.blocks.2.norm1.weight\",\n",
      "      \"encoder.blocks.2.norm1.bias\",\n",
      "      \"encoder.blocks.2.attn.q_bias\",\n",
      "      \"encoder.blocks.2.attn.v_bias\",\n",
      "      \"encoder.blocks.2.attn.proj.bias\",\n",
      "      \"encoder.blocks.2.norm2.weight\",\n",
      "      \"encoder.blocks.2.norm2.bias\",\n",
      "      \"encoder.blocks.2.mlp.fc1.bias\",\n",
      "      \"encoder.blocks.2.mlp.fc2.bias\"\n",
      "    ],\n",
      "    \"lr_scale\": 0.056313514709472656\n",
      "  },\n",
      "  \"layer_3_decay\": {\n",
      "    \"weight_decay\": 0.05,\n",
      "    \"params\": [\n",
      "      \"encoder.blocks.2.attn.qkv.weight\",\n",
      "      \"encoder.blocks.2.attn.proj.weight\",\n",
      "      \"encoder.blocks.2.mlp.fc1.weight\",\n",
      "      \"encoder.blocks.2.mlp.fc2.weight\"\n",
      "    ],\n",
      "    \"lr_scale\": 0.056313514709472656\n",
      "  },\n",
      "  \"layer_4_no_decay\": {\n",
      "    \"weight_decay\": 0.0,\n",
      "    \"params\": [\n",
      "      \"encoder.blocks.3.norm1.weight\",\n",
      "      \"encoder.blocks.3.norm1.bias\",\n",
      "      \"encoder.blocks.3.attn.q_bias\",\n",
      "      \"encoder.blocks.3.attn.v_bias\",\n",
      "      \"encoder.blocks.3.attn.proj.bias\",\n",
      "      \"encoder.blocks.3.norm2.weight\",\n",
      "      \"encoder.blocks.3.norm2.bias\",\n",
      "      \"encoder.blocks.3.mlp.fc1.bias\",\n",
      "      \"encoder.blocks.3.mlp.fc2.bias\"\n",
      "    ],\n",
      "    \"lr_scale\": 0.07508468627929688\n",
      "  },\n",
      "  \"layer_4_decay\": {\n",
      "    \"weight_decay\": 0.05,\n",
      "    \"params\": [\n",
      "      \"encoder.blocks.3.attn.qkv.weight\",\n",
      "      \"encoder.blocks.3.attn.proj.weight\",\n",
      "      \"encoder.blocks.3.mlp.fc1.weight\",\n",
      "      \"encoder.blocks.3.mlp.fc2.weight\"\n",
      "    ],\n",
      "    \"lr_scale\": 0.07508468627929688\n",
      "  },\n",
      "  \"layer_5_no_decay\": {\n",
      "    \"weight_decay\": 0.0,\n",
      "    \"params\": [\n",
      "      \"encoder.blocks.4.norm1.weight\",\n",
      "      \"encoder.blocks.4.norm1.bias\",\n",
      "      \"encoder.blocks.4.attn.q_bias\",\n",
      "      \"encoder.blocks.4.attn.v_bias\",\n",
      "      \"encoder.blocks.4.attn.proj.bias\",\n",
      "      \"encoder.blocks.4.norm2.weight\",\n",
      "      \"encoder.blocks.4.norm2.bias\",\n",
      "      \"encoder.blocks.4.mlp.fc1.bias\",\n",
      "      \"encoder.blocks.4.mlp.fc2.bias\"\n",
      "    ],\n",
      "    \"lr_scale\": 0.1001129150390625\n",
      "  },\n",
      "  \"layer_5_decay\": {\n",
      "    \"weight_decay\": 0.05,\n",
      "    \"params\": [\n",
      "      \"encoder.blocks.4.attn.qkv.weight\",\n",
      "      \"encoder.blocks.4.attn.proj.weight\",\n",
      "      \"encoder.blocks.4.mlp.fc1.weight\",\n",
      "      \"encoder.blocks.4.mlp.fc2.weight\"\n",
      "    ],\n",
      "    \"lr_scale\": 0.1001129150390625\n",
      "  },\n",
      "  \"layer_6_no_decay\": {\n",
      "    \"weight_decay\": 0.0,\n",
      "    \"params\": [\n",
      "      \"encoder.blocks.5.norm1.weight\",\n",
      "      \"encoder.blocks.5.norm1.bias\",\n",
      "      \"encoder.blocks.5.attn.q_bias\",\n",
      "      \"encoder.blocks.5.attn.v_bias\",\n",
      "      \"encoder.blocks.5.attn.proj.bias\",\n",
      "      \"encoder.blocks.5.norm2.weight\",\n",
      "      \"encoder.blocks.5.norm2.bias\",\n",
      "      \"encoder.blocks.5.mlp.fc1.bias\",\n",
      "      \"encoder.blocks.5.mlp.fc2.bias\"\n",
      "    ],\n",
      "    \"lr_scale\": 0.13348388671875\n",
      "  },\n",
      "  \"layer_6_decay\": {\n",
      "    \"weight_decay\": 0.05,\n",
      "    \"params\": [\n",
      "      \"encoder.blocks.5.attn.qkv.weight\",\n",
      "      \"encoder.blocks.5.attn.proj.weight\",\n",
      "      \"encoder.blocks.5.mlp.fc1.weight\",\n",
      "      \"encoder.blocks.5.mlp.fc2.weight\"\n",
      "    ],\n",
      "    \"lr_scale\": 0.13348388671875\n",
      "  },\n",
      "  \"layer_7_no_decay\": {\n",
      "    \"weight_decay\": 0.0,\n",
      "    \"params\": [\n",
      "      \"encoder.blocks.6.norm1.weight\",\n",
      "      \"encoder.blocks.6.norm1.bias\",\n",
      "      \"encoder.blocks.6.attn.q_bias\",\n",
      "      \"encoder.blocks.6.attn.v_bias\",\n",
      "      \"encoder.blocks.6.attn.proj.bias\",\n",
      "      \"encoder.blocks.6.norm2.weight\",\n",
      "      \"encoder.blocks.6.norm2.bias\",\n",
      "      \"encoder.blocks.6.mlp.fc1.bias\",\n",
      "      \"encoder.blocks.6.mlp.fc2.bias\"\n",
      "    ],\n",
      "    \"lr_scale\": 0.177978515625\n",
      "  },\n",
      "  \"layer_7_decay\": {\n",
      "    \"weight_decay\": 0.05,\n",
      "    \"params\": [\n",
      "      \"encoder.blocks.6.attn.qkv.weight\",\n",
      "      \"encoder.blocks.6.attn.proj.weight\",\n",
      "      \"encoder.blocks.6.mlp.fc1.weight\",\n",
      "      \"encoder.blocks.6.mlp.fc2.weight\"\n",
      "    ],\n",
      "    \"lr_scale\": 0.177978515625\n",
      "  },\n",
      "  \"layer_8_no_decay\": {\n",
      "    \"weight_decay\": 0.0,\n",
      "    \"params\": [\n",
      "      \"encoder.blocks.7.norm1.weight\",\n",
      "      \"encoder.blocks.7.norm1.bias\",\n",
      "      \"encoder.blocks.7.attn.q_bias\",\n",
      "      \"encoder.blocks.7.attn.v_bias\",\n",
      "      \"encoder.blocks.7.attn.proj.bias\",\n",
      "      \"encoder.blocks.7.norm2.weight\",\n",
      "      \"encoder.blocks.7.norm2.bias\",\n",
      "      \"encoder.blocks.7.mlp.fc1.bias\",\n",
      "      \"encoder.blocks.7.mlp.fc2.bias\"\n",
      "    ],\n",
      "    \"lr_scale\": 0.2373046875\n",
      "  },\n",
      "  \"layer_8_decay\": {\n",
      "    \"weight_decay\": 0.05,\n",
      "    \"params\": [\n",
      "      \"encoder.blocks.7.attn.qkv.weight\",\n",
      "      \"encoder.blocks.7.attn.proj.weight\",\n",
      "      \"encoder.blocks.7.mlp.fc1.weight\",\n",
      "      \"encoder.blocks.7.mlp.fc2.weight\"\n",
      "    ],\n",
      "    \"lr_scale\": 0.2373046875\n",
      "  },\n",
      "  \"layer_9_no_decay\": {\n",
      "    \"weight_decay\": 0.0,\n",
      "    \"params\": [\n",
      "      \"encoder.blocks.8.norm1.weight\",\n",
      "      \"encoder.blocks.8.norm1.bias\",\n",
      "      \"encoder.blocks.8.attn.q_bias\",\n",
      "      \"encoder.blocks.8.attn.v_bias\",\n",
      "      \"encoder.blocks.8.attn.proj.bias\",\n",
      "      \"encoder.blocks.8.norm2.weight\",\n",
      "      \"encoder.blocks.8.norm2.bias\",\n",
      "      \"encoder.blocks.8.mlp.fc1.bias\",\n",
      "      \"encoder.blocks.8.mlp.fc2.bias\"\n",
      "    ],\n",
      "    \"lr_scale\": 0.31640625\n",
      "  },\n",
      "  \"layer_9_decay\": {\n",
      "    \"weight_decay\": 0.05,\n",
      "    \"params\": [\n",
      "      \"encoder.blocks.8.attn.qkv.weight\",\n",
      "      \"encoder.blocks.8.attn.proj.weight\",\n",
      "      \"encoder.blocks.8.mlp.fc1.weight\",\n",
      "      \"encoder.blocks.8.mlp.fc2.weight\"\n",
      "    ],\n",
      "    \"lr_scale\": 0.31640625\n",
      "  },\n",
      "  \"layer_10_no_decay\": {\n",
      "    \"weight_decay\": 0.0,\n",
      "    \"params\": [\n",
      "      \"encoder.blocks.9.norm1.weight\",\n",
      "      \"encoder.blocks.9.norm1.bias\",\n",
      "      \"encoder.blocks.9.attn.q_bias\",\n",
      "      \"encoder.blocks.9.attn.v_bias\",\n",
      "      \"encoder.blocks.9.attn.proj.bias\",\n",
      "      \"encoder.blocks.9.norm2.weight\",\n",
      "      \"encoder.blocks.9.norm2.bias\",\n",
      "      \"encoder.blocks.9.mlp.fc1.bias\",\n",
      "      \"encoder.blocks.9.mlp.fc2.bias\"\n",
      "    ],\n",
      "    \"lr_scale\": 0.421875\n",
      "  },\n",
      "  \"layer_10_decay\": {\n",
      "    \"weight_decay\": 0.05,\n",
      "    \"params\": [\n",
      "      \"encoder.blocks.9.attn.qkv.weight\",\n",
      "      \"encoder.blocks.9.attn.proj.weight\",\n",
      "      \"encoder.blocks.9.mlp.fc1.weight\",\n",
      "      \"encoder.blocks.9.mlp.fc2.weight\"\n",
      "    ],\n",
      "    \"lr_scale\": 0.421875\n",
      "  },\n",
      "  \"layer_11_no_decay\": {\n",
      "    \"weight_decay\": 0.0,\n",
      "    \"params\": [\n",
      "      \"encoder.blocks.10.norm1.weight\",\n",
      "      \"encoder.blocks.10.norm1.bias\",\n",
      "      \"encoder.blocks.10.attn.q_bias\",\n",
      "      \"encoder.blocks.10.attn.v_bias\",\n",
      "      \"encoder.blocks.10.attn.proj.bias\",\n",
      "      \"encoder.blocks.10.norm2.weight\",\n",
      "      \"encoder.blocks.10.norm2.bias\",\n",
      "      \"encoder.blocks.10.mlp.fc1.bias\",\n",
      "      \"encoder.blocks.10.mlp.fc2.bias\"\n",
      "    ],\n",
      "    \"lr_scale\": 0.5625\n",
      "  },\n",
      "  \"layer_11_decay\": {\n",
      "    \"weight_decay\": 0.05,\n",
      "    \"params\": [\n",
      "      \"encoder.blocks.10.attn.qkv.weight\",\n",
      "      \"encoder.blocks.10.attn.proj.weight\",\n",
      "      \"encoder.blocks.10.mlp.fc1.weight\",\n",
      "      \"encoder.blocks.10.mlp.fc2.weight\"\n",
      "    ],\n",
      "    \"lr_scale\": 0.5625\n",
      "  },\n",
      "  \"layer_12_no_decay\": {\n",
      "    \"weight_decay\": 0.0,\n",
      "    \"params\": [\n",
      "      \"encoder.blocks.11.norm1.weight\",\n",
      "      \"encoder.blocks.11.norm1.bias\",\n",
      "      \"encoder.blocks.11.attn.q_bias\",\n",
      "      \"encoder.blocks.11.attn.v_bias\",\n",
      "      \"encoder.blocks.11.attn.proj.bias\",\n",
      "      \"encoder.blocks.11.norm2.weight\",\n",
      "      \"encoder.blocks.11.norm2.bias\",\n",
      "      \"encoder.blocks.11.mlp.fc1.bias\",\n",
      "      \"encoder.blocks.11.mlp.fc2.bias\"\n",
      "    ],\n",
      "    \"lr_scale\": 0.75\n",
      "  },\n",
      "  \"layer_12_decay\": {\n",
      "    \"weight_decay\": 0.05,\n",
      "    \"params\": [\n",
      "      \"encoder.blocks.11.attn.qkv.weight\",\n",
      "      \"encoder.blocks.11.attn.proj.weight\",\n",
      "      \"encoder.blocks.11.mlp.fc1.weight\",\n",
      "      \"encoder.blocks.11.mlp.fc2.weight\"\n",
      "    ],\n",
      "    \"lr_scale\": 0.75\n",
      "  },\n",
      "  \"layer_13_no_decay\": {\n",
      "    \"weight_decay\": 0.0,\n",
      "    \"params\": [\n",
      "      \"encoder.norm.weight\",\n",
      "      \"encoder.norm.bias\",\n",
      "      \"head_exp.head.bias\"\n",
      "    ],\n",
      "    \"lr_scale\": 1.0\n",
      "  },\n",
      "  \"layer_13_decay\": {\n",
      "    \"weight_decay\": 0.05,\n",
      "    \"params\": [\n",
      "      \"head_exp.head.weight\"\n",
      "    ],\n",
      "    \"lr_scale\": 1.0\n",
      "  }\n",
      "}\n",
      "optimizer settings: {'lr': 0.0001, 'weight_decay': 0.0, 'eps': 1e-08, 'betas': [0.9, 0.999]}\n",
      "Set warmup steps = 336\n",
      "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xf2217/Softwares/.micromamba/envs/get/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:420: Consider setting `persistent_workers=True` in 'val_dataloader' to speed up the dataloader worker initialization.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'exit' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/Softwares/.micromamba/envs/get/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py:47\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39mtrainer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 47\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n",
      "File \u001b[0;32m~/Softwares/.micromamba/envs/get/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:575\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    569\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39m_select_ckpt_path(\n\u001b[1;32m    570\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn,\n\u001b[1;32m    571\u001b[0m     ckpt_path,\n\u001b[1;32m    572\u001b[0m     model_provided\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    573\u001b[0m     model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    574\u001b[0m )\n\u001b[0;32m--> 575\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n",
      "File \u001b[0;32m~/Softwares/.micromamba/envs/get/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:982\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m    979\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    980\u001b[0m \u001b[38;5;66;03m# RUN THE TRAINER\u001b[39;00m\n\u001b[1;32m    981\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m--> 982\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    984\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    985\u001b[0m \u001b[38;5;66;03m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[1;32m    986\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n",
      "File \u001b[0;32m~/Softwares/.micromamba/envs/get/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:1024\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1023\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m isolate_rng():\n\u001b[0;32m-> 1024\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_sanity_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1025\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mset_detect_anomaly(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_detect_anomaly):\n",
      "File \u001b[0;32m~/Softwares/.micromamba/envs/get/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:1053\u001b[0m, in \u001b[0;36mTrainer._run_sanity_check\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1052\u001b[0m \u001b[38;5;66;03m# run eval step\u001b[39;00m\n\u001b[0;32m-> 1053\u001b[0m \u001b[43mval_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1055\u001b[0m call\u001b[38;5;241m.\u001b[39m_call_callback_hooks(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_sanity_check_end\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Softwares/.micromamba/envs/get/lib/python3.10/site-packages/lightning/pytorch/loops/utilities.py:179\u001b[0m, in \u001b[0;36m_no_grad_context.<locals>._decorator\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context_manager():\n\u001b[0;32m--> 179\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloop_run\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Softwares/.micromamba/envs/get/lib/python3.10/site-packages/lightning/pytorch/loops/evaluation_loop.py:122\u001b[0m, in \u001b[0;36m_EvaluationLoop.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m []\n\u001b[0;32m--> 122\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_run_start()\n",
      "File \u001b[0;32m~/Softwares/.micromamba/envs/get/lib/python3.10/site-packages/lightning/pytorch/loops/evaluation_loop.py:258\u001b[0m, in \u001b[0;36m_EvaluationLoop.reset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    257\u001b[0m data_fetcher\u001b[38;5;241m.\u001b[39msetup(combined_loader)\n\u001b[0;32m--> 258\u001b[0m \u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata_fetcher\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# creates the iterator inside the fetcher\u001b[39;00m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;66;03m# add the previous `fetched` value to properly track `is_last_batch` with no prefetching\u001b[39;00m\n",
      "File \u001b[0;32m~/Softwares/.micromamba/envs/get/lib/python3.10/site-packages/lightning/pytorch/loops/fetchers.py:105\u001b[0m, in \u001b[0;36m_PrefetchDataFetcher.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_PrefetchDataFetcher\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 105\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__iter__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    106\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    107\u001b[0m         \u001b[38;5;66;03m# ignore pre-fetching, it's not necessary\u001b[39;00m\n",
      "File \u001b[0;32m~/Softwares/.micromamba/envs/get/lib/python3.10/site-packages/lightning/pytorch/loops/fetchers.py:52\u001b[0m, in \u001b[0;36m_DataFetcher.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_DataFetcher\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 52\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcombined_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreset()\n",
      "File \u001b[0;32m~/Softwares/.micromamba/envs/get/lib/python3.10/site-packages/lightning/pytorch/utilities/combined_loader.py:351\u001b[0m, in \u001b[0;36mCombinedLoader.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    350\u001b[0m iterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mflattened, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_limits)\n\u001b[0;32m--> 351\u001b[0m \u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator \u001b[38;5;241m=\u001b[39m iterator\n",
      "File \u001b[0;32m~/Softwares/.micromamba/envs/get/lib/python3.10/site-packages/lightning/pytorch/utilities/combined_loader.py:155\u001b[0m, in \u001b[0;36m_Sequential.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 155\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_current_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/Softwares/.micromamba/envs/get/lib/python3.10/site-packages/lightning/pytorch/utilities/combined_loader.py:173\u001b[0m, in \u001b[0;36m_Sequential._load_current_iterator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator_idx \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miterables):\n\u001b[0;32m--> 173\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miterators \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterables\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iterator_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m]\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    175\u001b[0m     \u001b[38;5;66;03m# No more iterables to step through, return an empty list\u001b[39;00m\n",
      "File \u001b[0;32m~/Softwares/.micromamba/envs/get/lib/python3.10/site-packages/torch/utils/data/dataloader.py:484\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    483\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 484\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Softwares/.micromamba/envs/get/lib/python3.10/site-packages/torch/utils/data/dataloader.py:415\u001b[0m, in \u001b[0;36mDataLoader._get_iterator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    414\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_worker_number_rationality()\n\u001b[0;32m--> 415\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_MultiProcessingDataLoaderIter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Softwares/.micromamba/envs/get/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1138\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter.__init__\u001b[0;34m(self, loader)\u001b[0m\n\u001b[1;32m   1132\u001b[0m \u001b[38;5;66;03m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[1;32m   1133\u001b[0m \u001b[38;5;66;03m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[1;32m   1134\u001b[0m \u001b[38;5;66;03m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[1;32m   1135\u001b[0m \u001b[38;5;66;03m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[1;32m   1136\u001b[0m \u001b[38;5;66;03m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[1;32m   1137\u001b[0m \u001b[38;5;66;03m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[0;32m-> 1138\u001b[0m \u001b[43mw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1139\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_queues\u001b[38;5;241m.\u001b[39mappend(index_queue)\n",
      "File \u001b[0;32m~/Softwares/.micromamba/envs/get/lib/python3.10/multiprocessing/process.py:121\u001b[0m, in \u001b[0;36mBaseProcess.start\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    120\u001b[0m _cleanup()\n\u001b[0;32m--> 121\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sentinel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen\u001b[38;5;241m.\u001b[39msentinel\n",
      "File \u001b[0;32m~/Softwares/.micromamba/envs/get/lib/python3.10/multiprocessing/context.py:224\u001b[0m, in \u001b[0;36mProcess._Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[0;32m--> 224\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mProcess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Softwares/.micromamba/envs/get/lib/python3.10/multiprocessing/context.py:288\u001b[0m, in \u001b[0;36mSpawnProcess._Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpopen_spawn_posix\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Popen\n\u001b[0;32m--> 288\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Softwares/.micromamba/envs/get/lib/python3.10/multiprocessing/popen_spawn_posix.py:32\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fds \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 32\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Softwares/.micromamba/envs/get/lib/python3.10/multiprocessing/popen_fork.py:19\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinalizer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_launch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Softwares/.micromamba/envs/get/lib/python3.10/multiprocessing/popen_spawn_posix.py:62\u001b[0m, in \u001b[0;36mPopen._launch\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(parent_w, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m, closefd\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m---> 62\u001b[0m         \u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetbuffer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#%%\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# first run the model without initializing with a pretrain checkpoint\u001b[39;00m\n\u001b[1;32m      3\u001b[0m cfg\u001b[38;5;241m.\u001b[39mfinetune\u001b[38;5;241m.\u001b[39mcheckpoint \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m trainer \u001b[38;5;241m=\u001b[39m \u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Repos/get_model/get_model/run_region.py:433\u001b[0m, in \u001b[0;36mrun_zarr\u001b[0;34m(cfg)\u001b[0m\n\u001b[1;32m    430\u001b[0m dm \u001b[38;5;241m=\u001b[39m RegionZarrDataModule(cfg)\n\u001b[1;32m    431\u001b[0m model\u001b[38;5;241m.\u001b[39mdm \u001b[38;5;241m=\u001b[39m dm\n\u001b[0;32m--> 433\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrun_shared\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdm\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Repos/get_model/get_model/run.py:698\u001b[0m, in \u001b[0;36mrun_shared\u001b[0;34m(cfg, model, dm)\u001b[0m\n\u001b[1;32m    695\u001b[0m trainer \u001b[38;5;241m=\u001b[39m setup_trainer(cfg)\n\u001b[1;32m    697\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cfg\u001b[38;5;241m.\u001b[39mstage \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 698\u001b[0m     \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfinetune\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresume_ckpt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    699\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cfg\u001b[38;5;241m.\u001b[39mstage \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidate\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    700\u001b[0m     trainer\u001b[38;5;241m.\u001b[39mvalidate(model, datamodule\u001b[38;5;241m=\u001b[39mdm, ckpt_path\u001b[38;5;241m=\u001b[39mcfg\u001b[38;5;241m.\u001b[39mfinetune\u001b[38;5;241m.\u001b[39mresume_ckpt)\n",
      "File \u001b[0;32m~/Softwares/.micromamba/envs/get/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:539\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m=\u001b[39m TrainerStatus\u001b[38;5;241m.\u001b[39mRUNNING\n\u001b[1;32m    538\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 539\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    540\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[1;32m    541\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Softwares/.micromamba/envs/get/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py:64\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(launcher, _SubprocessScriptLauncher):\n\u001b[1;32m     63\u001b[0m         launcher\u001b[38;5;241m.\u001b[39mkill(_get_sigkill_signal())\n\u001b[0;32m---> 64\u001b[0m     \u001b[43mexit\u001b[49m(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exception:\n\u001b[1;32m     67\u001b[0m     _interrupt(trainer, exception)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'exit' is not defined"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "# first run the model without initializing with a pretrain checkpoint\n",
    "cfg.finetune.checkpoint = None\n",
    "trainer = run(cfg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training speed is almost on par with a 3090 suprisingly...However something in the validation step has not fully utilized the MPS accelarator which make it a bit slow..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train_atpm_loss': tensor(0.4894),\n",
       " 'train_loss': tensor(0.4894),\n",
       " 'val_atpm_loss': tensor(0.4842),\n",
       " 'atpm_pearson': tensor(0.6565),\n",
       " 'atpm_spearman': tensor(0.4794),\n",
       " 'atpm_r2': tensor(0.3233),\n",
       " 'val_loss': tensor(0.4842)}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#%%\n",
    "trainer.callback_metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Training With Pretrained Checkpoint\n",
    "\n",
    "\n",
    "\n",
    " Now, let's train the model using a pretrained checkpoint. This checkpoint was trained on a large dataset\n",
    "\n",
    " and should help the model learn faster and potentially achieve better performance.\n",
    "\n",
    "\n",
    "\n",
    " Note: You'll need to download the checkpoint first:\n",
    "\n",
    " ```bash\n",
    "\n",
    " aws s3 cp s3://2023-get-xf2217/get_demo/checkpoints/regulatory_inference_checkpoint_fetal_adult/pretrain_fetal_adult/checkpoint-799.pth ./checkpoint-799.pth\n",
    "\n",
    " ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "# now train the model with a pretrain checkpoint\n",
    "cfg.finetune.checkpoint = './checkpoint-799.pth'\n",
    "cfg.run.run_name = 'predict_atac_with_pretrain'\n",
    "cfg.finetune.strict = False # need this because the original checkpoint has a mask-prediction header\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train_atpm_loss': tensor(0.4900),\n",
       " 'train_loss': tensor(0.4900),\n",
       " 'val_atpm_loss': tensor(0.4761),\n",
       " 'atpm_pearson': tensor(0.6761),\n",
       " 'atpm_spearman': tensor(0.4886),\n",
       " 'atpm_r2': tensor(0.4412),\n",
       " 'val_loss': tensor(0.4761)}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = run(cfg)\n",
    "trainer.callback_metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results Analysis\n",
    "\n",
    "Looking at the results, we can see that the pretrained model yields better results than trained from scratch. If you look at the validation loss curve on wandb, you will find that the pretrained version is always lower than the from-scratch version.\n",
    "\n",
    "This demonstrates the value of transfer learning in genomics - the pretrained model has already learned useful features about the relationship between motifs and chromatin accessibility."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretation analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's say we want to examine the contributor to chromatin accessibility at several gene's promoters, the gene list are defined in `cfg.task.gene_list`. You can also set it to `None` to infer all genes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MYC,SOX10,SOX2,RET'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg.task.gene_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run inference to get the jacobian matrix for genes\n",
    "# Setup config first. Change state to 'predict'\n",
    "cfg.stage = 'predict'\n",
    "cfg.machine.batch_size=1\n",
    "# resume from the best checkpoint we just traineds\n",
    "cfg.finetune.checkpoint = None\n",
    "cfg.finetune.resume_ckpt = '/Users/xf2217/Downloads/finetune_tutorial/predict_atac_with_pretrain/checkpoints/best.ckpt' #trainer.checkpoint_callback.best_model_path\n",
    "cfg.run.run_name='interpret'\n",
    "# save config to yaml in case we need to resume from it\n",
    "from omegaconf import OmegaConf\n",
    "OmegaConf.save(cfg, 'interpret_cfg.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xf2217/Softwares/.micromamba/envs/get/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: Metric `SpearmanCorrcoef` will save all targets and predictions in the buffer. For large datasets, this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)  # noqa: B028\n",
      "/Users/xf2217/Softwares/.micromamba/envs/get/lib/python3.10/site-packages/lightning/pytorch/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "100%|██████████| 1/1 [00:00<00:00, 75.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leave out chromosomes: ['chr10', 'chr11']\n",
      "Input chromosomes: ['chr10', 'chr11']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xf2217/Softwares/.micromamba/envs/get/lib/python3.10/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:362: The dirpath has changed from '/Users/xf2217/Downloads/finetune_tutorial/predict_atac_with_pretrain/checkpoints' to '/Users/xf2217/Downloads/finetune_tutorial/interpret/checkpoints', therefore `best_model_score`, `kth_best_model_path`, `kth_value`, `last_model_path` and `best_k_models` won't be reloaded. Only `best_model_path` will be reloaded.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 6/6 [00:00<00:00, 14.54it/s]Saving to /Users/xf2217/Downloads/finetune_tutorial/interpret/interpret.zarr\n",
      "Predicting DataLoader 0: 100%|██████████| 6/6 [00:00<00:00, 13.90it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xf2217/Softwares/.micromamba/envs/get/lib/python3.10/site-packages/zarr/storage.py:455: UserWarning: an object_codec is only needed for object arrays\n",
      "  _init_array_metadata(\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">interpret</strong> at: <a href='https://wandb.ai/get-v3/finetune_tutorial/runs/cv4zt2s5' target=\"_blank\">https://wandb.ai/get-v3/finetune_tutorial/runs/cv4zt2s5</a><br> View project at: <a href='https://wandb.ai/get-v3/finetune_tutorial' target=\"_blank\">https://wandb.ai/get-v3/finetune_tutorial</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/Users/xf2217/Downloads/finetune_tutorial/interpret/wandb/run-20250103_004924-cv4zt2s5/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<lightning.pytorch.trainer.trainer.Trainer at 0x371209e40>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run model inference\n",
    "import os\n",
    "\n",
    "from get_model.config.config import load_config\n",
    "\n",
    "if os.path.exists('interpret_cfg.yaml'):\n",
    "    cfg = load_config('interpret_cfg.yaml', '../../tutorials')\n",
    "from get_model.run_region import run_zarr as run\n",
    "\n",
    "run(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GETHydraCelltype: None\n",
       "        Zarr path: /Users/xf2217/Downloads/finetune_tutorial/interpret/interpret.zarr\n",
       "        Number of regions per sample: 200\n",
       "        Number of features: 283\n",
       "        Number of genes: 6\n",
       "        Number of peaks: 1200\n",
       "        "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from gcell.cell.celltype import GETHydraCellType\n",
    "\n",
    "from get_model.config.config import load_config\n",
    "\n",
    "if os.path.exists('interpret_cfg.yaml'):\n",
    "    cfg = load_config('interpret_cfg.yaml', '../../tutorials')\n",
    "celltype = GETHydraCellType.from_config(cfg)\n",
    "celltype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.matrix.ClusterGrid at 0x3416aabf0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 300x300 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "d = celltype.gene_by_motif.data.T\n",
    "top_idx_for_each_column = []\n",
    "for i in range(d.shape[1]):\n",
    "    top_idx_for_each_column.append(d.iloc[:,i].abs().sort_values(ascending=False).index[:5])\n",
    "top_idx_for_each_column = np.unique(top_idx_for_each_column)\n",
    "sns.clustermap(d.loc[top_idx_for_each_column], center=0, cmap='RdBu_r', figsize=(3,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NFY              0.000294\n",
       "TBX/3            0.000311\n",
       "E2F/3            0.000349\n",
       "ZNF320           0.000404\n",
       "ZNF143           0.000538\n",
       "TATA             0.000555\n",
       "NRF1             0.000622\n",
       "KLF/SP/1         0.000741\n",
       "Accessibility    0.001023\n",
       "E2F/2            0.001256\n",
       "dtype: float32"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "celltype.get_gene_jacobian_summary('MYC', axis='motif').sort_values().tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<Figure size 1000x200 with 1 Axes>,\n",
       " <Axes: xlabel='Genomic Position on Chromosome 8                          '>)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "GETHydraCellType.plot_region(celltype.get_gene_jacobian_summary('MYC', axis='region'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Chromosome</th>\n",
       "      <th>Start</th>\n",
       "      <th>End</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>106</td>\n",
       "      <td>chr8</td>\n",
       "      <td>127738528</td>\n",
       "      <td>127738928</td>\n",
       "      <td>0.000141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>chr8</td>\n",
       "      <td>124973496</td>\n",
       "      <td>124973896</td>\n",
       "      <td>0.000144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>chr8</td>\n",
       "      <td>124998208</td>\n",
       "      <td>124998608</td>\n",
       "      <td>0.000152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>171</td>\n",
       "      <td>chr8</td>\n",
       "      <td>129998824</td>\n",
       "      <td>129999224</td>\n",
       "      <td>0.000167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>188</td>\n",
       "      <td>chr8</td>\n",
       "      <td>130333280</td>\n",
       "      <td>130333680</td>\n",
       "      <td>0.000169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>169</td>\n",
       "      <td>chr8</td>\n",
       "      <td>129983656</td>\n",
       "      <td>129984056</td>\n",
       "      <td>0.000171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>chr8</td>\n",
       "      <td>125413488</td>\n",
       "      <td>125413888</td>\n",
       "      <td>0.000176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>chr8</td>\n",
       "      <td>125427072</td>\n",
       "      <td>125427472</td>\n",
       "      <td>0.000231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>190</td>\n",
       "      <td>chr8</td>\n",
       "      <td>130357400</td>\n",
       "      <td>130357800</td>\n",
       "      <td>0.000269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>100</td>\n",
       "      <td>chr8</td>\n",
       "      <td>127735128</td>\n",
       "      <td>127735528</td>\n",
       "      <td>0.007869</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     index                      Chromosome      Start        End     Score\n",
       "106    106  chr8                            127738528  127738928  0.000141\n",
       "0        0  chr8                            124973496  124973896  0.000144\n",
       "1        1  chr8                            124998208  124998608  0.000152\n",
       "171    171  chr8                            129998824  129999224  0.000167\n",
       "188    188  chr8                            130333280  130333680  0.000169\n",
       "169    169  chr8                            129983656  129984056  0.000171\n",
       "23      23  chr8                            125413488  125413888  0.000176\n",
       "25      25  chr8                            125427072  125427472  0.000231\n",
       "190    190  chr8                            130357400  130357800  0.000269\n",
       "100    100  chr8                            127735128  127735528  0.007869"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "celltype.get_gene_jacobian_summary('MYC', axis='region').sort_values('Score').tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "E2F/3           -0.057657\n",
       "Accessibility   -0.045304\n",
       "NR/18           -0.031027\n",
       "ZNF320          -0.029208\n",
       "ZNF324          -0.024562\n",
       "                   ...   \n",
       "ZNF554           0.030869\n",
       "KLF/SP/1         0.040352\n",
       "ZNF143           0.053678\n",
       "E2F/2            0.072658\n",
       "TATA             0.104744\n",
       "Name: 100, Length: 282, dtype: object"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "celltype.get_gene_jacobian('MYC', multiply_input=True)[2].data[0:200].query('Start==127735128').T.iloc[6:, 0].sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"840\"\n",
       "            src=\"file:///var/folders/hr/7w6915r54zl8ym4yk2g9lmcw0000gn/T/tmpb8xpu0uu.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x103d939a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz.save_html('test.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
